{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "import os\n",
    "from sentence_transformers import SentenceTransformer, util\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.models import resnet50\n",
    "from torch.nn.functional import normalize\n",
    "pytesseract.pytesseract.tesseract_cmd = r'C:\\Program Files\\Tesseract-OCR\\tesseract.exe'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_from_image(image_path):\n",
    "    image = Image.open(image_path)\n",
    "    text = pytesseract.image_to_string(image)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_texts_from_folder(folder_path):\n",
    "    texts = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            texts[file_name] = extract_text_from_image(file_path)\n",
    "    return texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_visual_features(image_path, model, transform):\n",
    "    image = Image.open(image_path).convert('RGB')\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    with torch.no_grad():\n",
    "        features = model(image).squeeze()\n",
    "    return normalize(features, dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_visual_features_from_folder(folder_path, model, transform):\n",
    "    features = {}\n",
    "    for file_name in os.listdir(folder_path):\n",
    "        if file_name.endswith(('.png', '.jpg', '.jpeg')):\n",
    "            file_path = os.path.join(folder_path, file_name)\n",
    "            features[file_name] = extract_visual_features(file_path, model, transform)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_text_embeddings(texts):\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    embeddings = model.encode(list(texts.values()), convert_to_tensor=True)\n",
    "    return embeddings, list(texts.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_document(uploaded_text, uploaded_visual, folder_text_embeddings, folder_visual_features, folder_filenames):\n",
    "    model = SentenceTransformer('paraphrase-MiniLM-L6-v2')\n",
    "    uploaded_text_embedding = model.encode([uploaded_text], convert_to_tensor=True)\n",
    "    \n",
    "    text_scores = util.pytorch_cos_sim(uploaded_text_embedding, folder_text_embeddings)[0]\n",
    "    visual_scores = torch.tensor([torch.dot(uploaded_visual, folder_visual_features[fname]) for fname in folder_filenames])\n",
    "    \n",
    "    combined_scores = 0.5 * text_scores + 0.5 * visual_scores  # You can adjust the weights as needed\n",
    "    comparison_scores = {folder_filenames[i]: combined_scores[i].item() for i in range(len(folder_filenames))}\n",
    "    \n",
    "    return comparison_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_upload_and_compare(uploaded_file_path, folder_path):\n",
    "    # Extract text and visual features from the uploaded document\n",
    "    uploaded_text = extract_text_from_image(uploaded_file_path)\n",
    "    uploaded_visual = extract_visual_features(uploaded_file_path, resnet_model, transform)\n",
    "    \n",
    "    # Extract texts and embeddings from the folder\n",
    "    folder_texts = extract_texts_from_folder(folder_path)\n",
    "    folder_text_embeddings, folder_filenames = extract_text_embeddings(folder_texts)\n",
    "    \n",
    "    # Extract visual features from the folder\n",
    "    folder_visual_features = extract_visual_features_from_folder(folder_path, resnet_model, transform)\n",
    "    \n",
    "    # Compare the uploaded document against the folder documents\n",
    "    comparison_scores = compare_document(uploaded_text, uploaded_visual, folder_text_embeddings, folder_visual_features, folder_filenames)\n",
    "    \n",
    "    return comparison_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_upload_and_compare(uploaded_file_path, folder_path):\n",
    "    # Extract text and visual features from the uploaded document\n",
    "    uploaded_text = extract_text_from_image(uploaded_file_path)\n",
    "    uploaded_visual = extract_visual_features(uploaded_file_path, resnet_model, transform)\n",
    "    \n",
    "    # Extract texts and embeddings from the folder\n",
    "    folder_texts = extract_texts_from_folder(folder_path)\n",
    "    folder_text_embeddings, folder_filenames = extract_text_embeddings(folder_texts)\n",
    "    \n",
    "    # Extract visual features from the folder\n",
    "    folder_visual_features = extract_visual_features_from_folder(folder_path, resnet_model, transform)\n",
    "    \n",
    "    # Compare the uploaded document against the folder documents\n",
    "    comparison_scores = compare_document(uploaded_text, uploaded_visual, folder_text_embeddings, folder_visual_features, folder_filenames)\n",
    "    \n",
    "    # Get the top 3 highest scores\n",
    "    sorted_scores = sorted(comparison_scores.items(), key=lambda item: item[1], reverse=True)[:3]\n",
    "    \n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = \"C:/Users/Vivenns/OneDrive - Victorian Institute of Technology/Desktop/compare/document\"\n",
    "uploaded_file_path = \"C:/Users/Vivenns/OneDrive - Victorian Institute of Technology/Desktop/compare/document/pass (2).jpeg\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ResNet model and transform\n",
    "resnet_model = resnet50(pretrained=True)\n",
    "resnet_model.eval()\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "non_add (1).jpeg: 1.0000\n",
      "pass (2).jpeg: 1.0000\n",
      "bank (190).jpg: 0.7143\n"
     ]
    }
   ],
   "source": [
    "comparison_scores = process_upload_and_compare(uploaded_file_path, folder_path)\n",
    "for filename, score in comparison_scores:\n",
    "    print(f\"{filename}: {score:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
